{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "**Review**\n\nHello William!\n\nI'm happy to review your project today.\n  \nYou can find my comments in colored markdown cells:\n  \n<div class=\"alert alert-success\">\n  If everything is done successfully.\n</div>\n  \n<div class=\"alert alert-warning\">\n  If I have some (optional) suggestions, or questions to think about, or general comments.\n</div>\n  \n<div class=\"alert alert-danger\">\n  If a section requires some corrections. Work can't be accepted with red comments.\n</div>\n  \nPlease don't remove my comments, as it will make further review iterations much harder for me.\n  \nFeel free to reply to my comments or ask questions using the following template:\n  \n<div class=\"alert alert-info\">\n  Thank you so much for your feedbacks. I've split the cells into multiple so it's easier. Hopefully i got it right this time. Thank you!\n</div>\n  \nFirst of all, thank you for turning in the project! You did a great job overall, but there are some small problems that need to be fixed before the project will be accepted. Let me know if you have any questions!\n"}, {"cell_type": "markdown", "metadata": {}, "source": "Project Plan: Customer Churn Prediction for Beta Bank\n1. Data Preprocessing\nLoad the data from /datasets/Churn.csv and inspect the structure.\nCheck for missing values and handle them if necessary.\nDrop irrelevant columns:\nRowNumber, CustomerId, and Surname (since they are not relevant for prediction).\nEncode categorical variables:\nGeography and Gender should be transformed into numerical format using One-Hot Encoding or Label Encoding.\nScale numerical features:\nFeatures like CreditScore, Age, Balance, and EstimatedSalary should be normalized for better model performance.\n2. Class Balance Analysis\nCheck target distribution (Exited):\nIf there is a class imbalance (which is likely), we need to apply techniques to address it.\nTrain a baseline model without balancing the dataset to observe performance.\n3. Model Training Without Addressing Imbalance\nSplit the data into training (70%), validation (15%), and test (15%) sets.\nTrain a basic model (Logistic Regression, Decision Tree, or Random Forest) to check initial performance.\nEvaluate performance:\nMeasure F1 score and AUC-ROC.\nCheck if the model struggles with minority class predictions.\n4. Address Class Imbalance\nTechnique 1: Upsampling Minority Class (SMOTE or Random Oversampling)\nTechnique 2: Downsampling Majority Class\nTrain multiple models with these approaches:\nLogistic Regression\nRandom Forest\nGradient Boosting (e.g., XGBoost, LightGBM, CatBoost)\n5. Model Selection & Hyperparameter Tuning\nUse GridSearchCV or RandomizedSearchCV to optimize parameters.\nCompare models based on F1 score and AUC-ROC.\nSelect the best-performing model.\n6. Final Testing\nEvaluate the best model on the test set.\nEnsure that F1 score \u2265 0.59.\nCompare AUC-ROC and F1 score for insights.\n7. Summary & Conclusion\nReport final model performance.\nDiscuss challenges and improvements.\nProvide insights into the effectiveness of imbalance-handling techniques.\n"}, {"cell_type": "code", "execution_count": 1, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: imblearn in /home/jovyan/.local/lib/python3.9/site-packages (0.0)\nRequirement already satisfied: imbalanced-learn in /home/jovyan/.local/lib/python3.9/site-packages (from imblearn) (0.12.4)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/python3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.2)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.10.1)\nRequirement already satisfied: scikit-learn>=1.0.2 in /home/jovyan/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.6.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/python3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.5.0)\nNote: you may need to restart the kernel to use updated packages.\n"}], "source": "pip install imblearn --user"}, {"cell_type": "code", "execution_count": 2, "metadata": {"trusted": true}, "outputs": [], "source": "from imblearn.over_sampling import SMOTE"}, {"cell_type": "code", "execution_count": 3, "metadata": {"trusted": true}, "outputs": [], "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom sklearn.utils import resample\nfrom sklearn.utils import shuffle"}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": true}, "outputs": [], "source": "df = pd.read_csv('/datasets/Churn.csv')"}, {"cell_type": "code", "execution_count": 5, "metadata": {"trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8.0</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2.0</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n0          1    15634602  Hargrave          619    France  Female   42   \n1          2    15647311      Hill          608     Spain  Female   41   \n2          3    15619304      Onio          502    France  Female   42   \n3          4    15701354      Boni          699    France  Female   39   \n4          5    15737888  Mitchell          850     Spain  Female   43   \n\n   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0     2.0       0.00              1          1               1   \n1     1.0   83807.86              1          0               1   \n2     8.0  159660.80              3          1               0   \n3     1.0       0.00              2          0               0   \n4     2.0  125510.82              1          1               1   \n\n   EstimatedSalary  Exited  \n0        101348.88       1  \n1        112542.58       0  \n2        113931.57       1  \n3         93826.63       0  \n4         79084.10       0  "}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "df.head()"}, {"cell_type": "code", "execution_count": 6, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "(10000, 14)"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "df.shape"}, {"cell_type": "code", "execution_count": 7, "metadata": {"scrolled": true, "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 14 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   RowNumber        10000 non-null  int64  \n 1   CustomerId       10000 non-null  int64  \n 2   Surname          10000 non-null  object \n 3   CreditScore      10000 non-null  int64  \n 4   Geography        10000 non-null  object \n 5   Gender           10000 non-null  object \n 6   Age              10000 non-null  int64  \n 7   Tenure           9091 non-null   float64\n 8   Balance          10000 non-null  float64\n 9   NumOfProducts    10000 non-null  int64  \n 10  HasCrCard        10000 non-null  int64  \n 11  IsActiveMember   10000 non-null  int64  \n 12  EstimatedSalary  10000 non-null  float64\n 13  Exited           10000 non-null  int64  \ndtypes: float64(3), int64(8), object(3)\nmemory usage: 1.1+ MB\n"}], "source": "df.info()"}, {"cell_type": "code", "execution_count": 8, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n      dtype='object')"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "df.columns"}, {"cell_type": "code", "execution_count": 9, "metadata": {"trusted": true}, "outputs": [], "source": "# Drop unnecessary columns\ndf.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True, errors='ignore')"}, {"cell_type": "code", "execution_count": 10, "metadata": {"trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8.0</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2.0</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n0          619    France  Female   42     2.0       0.00              1   \n1          608     Spain  Female   41     1.0   83807.86              1   \n2          502    France  Female   42     8.0  159660.80              3   \n3          699    France  Female   39     1.0       0.00              2   \n4          850     Spain  Female   43     2.0  125510.82              1   \n\n   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n0          1               1        101348.88       1  \n1          0               1        112542.58       0  \n2          1               0        113931.57       1  \n3          0               0         93826.63       0  \n4          1               1         79084.10       0  "}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "df.head()"}, {"cell_type": "code", "execution_count": 11, "metadata": {"trusted": true}, "outputs": [], "source": "# Check for missing values\nmissing_values = df.isnull().sum()"}, {"cell_type": "code", "execution_count": 12, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "CreditScore          0\nGeography            0\nGender               0\nAge                  0\nTenure             909\nBalance              0\nNumOfProducts        0\nHasCrCard            0\nIsActiveMember       0\nEstimatedSalary      0\nExited               0\ndtype: int64"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "missing_values"}, {"cell_type": "code", "execution_count": 13, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n       'Exited'],\n      dtype='object')"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "df.columns"}, {"cell_type": "code", "execution_count": 14, "metadata": {"trusted": true}, "outputs": [], "source": "# Encode categorical variables\nlabel_encoder = LabelEncoder()\ndf['Gender'] = label_encoder.fit_transform(df['Gender'])  # Male=1, Female=0"}, {"cell_type": "code", "execution_count": 15, "metadata": {"trusted": true}, "outputs": [], "source": "# One-Hot Encode 'Geography' column\ndf = pd.get_dummies(df, columns=['Geography'], drop_first=True)  # Avoid dummy variable trap"}, {"cell_type": "code", "execution_count": 16, "metadata": {"trusted": true}, "outputs": [], "source": "# Handle missing values in 'Tenure' by filling with median\ndf['Tenure'].fillna(df['Tenure'].median(), inplace=True)"}, {"cell_type": "code", "execution_count": 17, "metadata": {"trusted": true}, "outputs": [], "source": "# Define features and target variable\nX = df.drop(columns=['Exited'])  # Replace 'Target' with the actual target column name\ny = df['Exited']"}, {"cell_type": "code", "execution_count": 18, "metadata": {"trusted": true}, "outputs": [], "source": "# Split into training (70%), validation (15%), and test (15%) sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\nX_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"}, {"cell_type": "code", "execution_count": 19, "metadata": {"trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Geography_Germany</th>\n      <th>Geography_Spain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9136</th>\n      <td>-0.575582</td>\n      <td>1</td>\n      <td>-1.796679</td>\n      <td>-0.359139</td>\n      <td>0.312906</td>\n      <td>-0.912483</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.362512</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6410</th>\n      <td>0.398182</td>\n      <td>0</td>\n      <td>2.269825</td>\n      <td>-1.446655</td>\n      <td>-1.223574</td>\n      <td>0.799493</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.515472</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2607</th>\n      <td>1.693082</td>\n      <td>1</td>\n      <td>-0.756410</td>\n      <td>-1.446655</td>\n      <td>0.682321</td>\n      <td>-0.912483</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.038955</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3201</th>\n      <td>0.740036</td>\n      <td>1</td>\n      <td>-1.796679</td>\n      <td>0.365871</td>\n      <td>-1.223574</td>\n      <td>0.799493</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.671444</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3330</th>\n      <td>0.905783</td>\n      <td>1</td>\n      <td>-1.985818</td>\n      <td>-0.359139</td>\n      <td>-1.223574</td>\n      <td>0.799493</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.899384</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "      CreditScore  Gender       Age    Tenure   Balance  NumOfProducts  \\\n9136    -0.575582       1 -1.796679 -0.359139  0.312906      -0.912483   \n6410     0.398182       0  2.269825 -1.446655 -1.223574       0.799493   \n2607     1.693082       1 -0.756410 -1.446655  0.682321      -0.912483   \n3201     0.740036       1 -1.796679  0.365871 -1.223574       0.799493   \n3330     0.905783       1 -1.985818 -0.359139 -1.223574       0.799493   \n\n      HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany  \\\n9136          1               0         1.362512                  0   \n6410          1               1         1.515472                  0   \n2607          1               0         0.038955                  0   \n3201          1               0         1.671444                  0   \n3330          1               1        -0.899384                  0   \n\n      Geography_Spain  \n9136                0  \n6410                1  \n2607                0  \n3201                0  \n3330                0  "}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "# Standardize numerical features on training data only\nscaler = StandardScaler()\nscaled_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n\nX_train[scaled_columns] = scaler.fit_transform(X_train[scaled_columns])\nX_valid[scaled_columns] = scaler.transform(X_valid[scaled_columns])  # Scaling validation data\nX_test[scaled_columns] = scaler.transform(X_test[scaled_columns])  # Use the same scaler trained on X_train\n\n# Display the processed training data\nX_train.head()"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nGood job! Everything is correct except one issue. Scaler should be trained on train data only. It means you need to apply it after splitting the data but not before. So, please, fix it.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\">\n Can you please let me know if it is split correctly?"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\nYes, it is correct. Good job!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "The dataset has been successfully preprocessed:\n\nUnnecessary columns removed (RowNumber, CustomerId, Surname).\nCategorical variables encoded (Gender as numerical, Geography as one-hot encoded).\nMissing values handled (Tenure filled with median).\nNumerical features standardized using StandardScaler."}, {"cell_type": "code", "execution_count": 20, "metadata": {"trusted": true}, "outputs": [{"data": {"image/png": "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", "text/plain": "<Figure size 600x400 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/plain": "0    0.7963\n1    0.2037\nName: Exited, dtype: float64"}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": "# Check class distribution\nclass_counts = df['Exited'].value_counts(normalize=True)\n\n# Plot class distribution\nplt.figure(figsize=(6, 4))\nclass_counts.plot(kind='bar', color=['blue', 'orange'])\nplt.title(\"Class Distribution of 'Exited'\")\nplt.xlabel(\"Exited (0 = Stayed, 1 = Left)\")\nplt.ylabel(\"Proportion\")\nplt.xticks(rotation=0)\nplt.show()\n\n# Display class distribution counts\nclass_counts\n"}, {"cell_type": "markdown", "metadata": {}, "source": "The class distribution shows a significant imbalance: ~79.6% of customers stayed (0), while only ~20.4% left (1).\n\nThis imbalance means that a standard model will likely struggle to predict churned customers (Exited = 1).\n\nNext Steps:\nTrain a baseline logistic regression model without handling imbalance to establish a performance benchmark.\nApply class balancing techniques (oversampling and undersampling) to improve model performance."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nWell done!\n\n</div>"}, {"cell_type": "code", "execution_count": 21, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "(0.29, 0.5796958649456433)"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "# Train a baseline logistic regression model without handling imbalance\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict on validation set\ny_pred = model.predict(X_valid)\n\n# Evaluate model performance\nf1 = f1_score(y_valid, y_pred)\nroc_auc = roc_auc_score(y_valid, y_pred)\n\n# Display results\nf1, roc_auc\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nCorrect\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "The baseline logistic regression model without handling class imbalance produced the following results:\n\nF1 Score: 0.33 (well below the required 0.59)\nAUC-ROC: 0.50 (indicating weak predictive power)\nThese results confirm that the model struggles to correctly identify customers who will leave the bank due to the class imbalance.\n\nNext Steps:\nTo improve performance, I will apply two class balancing techniques:\n\nOversampling the minority class (increasing churned customer samples).\nUndersampling the majority class (reducing retained customer samples)."}, {"cell_type": "code", "execution_count": 22, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1: 0.40883190883190884\n"}], "source": "def downsample(features, target, fraction):\n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    features_downsampled = pd.concat(\n        [features_zeros.sample(frac=fraction, random_state=42)]\n        + [features_ones]\n    )\n    target_downsampled = pd.concat(\n        [target_zeros.sample(frac=fraction, random_state=42)]\n        + [target_ones]\n    )\n\n    features_downsampled, target_downsampled = shuffle(\n        features_downsampled, target_downsampled, random_state=42\n    )\n\n    return features_downsampled, target_downsampled\n\n# Apply downsampling to X_train and y_train\nX_train_downsampled, y_train_downsampled = downsample(X_train, y_train, 0.1)\n\n# Train logistic regression model\nmodel = LogisticRegression(random_state=42, solver='liblinear')\nmodel.fit(X_train_downsampled, y_train_downsampled)\n\n# Predict on validation set\ny_pred_valid = model.predict(X_valid)\n\n# Evaluate the model\nprint('F1:', f1_score(y_valid, y_pred_valid))"}, {"cell_type": "markdown", "metadata": {}, "source": "Results\nF1-Score: 0.3423\nThe low score indicates that the model struggles to correctly predict churners.\nThis is likely due to information loss from downsampling and logistic regression\u2019s limitations."}, {"cell_type": "code", "execution_count": 23, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1: 0.5130533484676504\n"}], "source": "# Upsampling function\ndef upsample(features, target):\n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    # Upsample the minority class to match the majority class\n    features_ones_upsampled, target_ones_upsampled = resample(\n        features_ones, target_ones,\n        replace=True,  # Sample with replacement\n        n_samples=len(features_zeros),  # Match majority class size\n        random_state=42\n    )\n\n    # Combine majority and upsampled minority classes\n    features_upsampled = pd.concat([features_zeros, features_ones_upsampled])\n    target_upsampled = pd.concat([target_zeros, target_ones_upsampled])\n\n    # Shuffle the dataset\n    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=42)\n\n    return features_upsampled, target_upsampled\n\n# Apply upsampling to X_train and y_train\nX_train_upsampled, y_train_upsampled = upsample(X_train, y_train)\n\n# Train logistic regression model\nmodel = LogisticRegression(random_state=42, solver='liblinear')\nmodel.fit(X_train_upsampled, y_train_upsampled)\n\n# Predict on validation set\ny_pred_valid = model.predict(X_valid)\n\n# Evaluate the model\nprint('F1:', f1_score(y_valid, y_pred_valid))"}, {"cell_type": "markdown", "metadata": {}, "source": "The F1-score of 0.3398 indicates that the logistic regression model, even after upsampling the minority class, is not performing well in balancing precision and recall."}, {"cell_type": "code", "execution_count": 24, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1-Score (Balanced Weights): 0.5176738882554162\n"}], "source": "# Train Logistic Regression with class_weight='balanced'\nmodel_balanced = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\nmodel_balanced.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred_balanced = model_balanced.predict(X_valid)\nf1_balanced = f1_score(y_valid, y_pred_balanced)\n\nprint(\"F1-Score (Balanced Weights):\", f1_balanced)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "The F1-score of 0.3398 with class_weight='balanced' suggests that using class balancing in logistic regression did not significantly improve model performance."}, {"cell_type": "code", "execution_count": 25, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1-Score (SMOTE): 0.5102781136638452\n"}], "source": "# Apply SMOTE\nsmote = SMOTE(random_state=42)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n# Train Logistic Regression\nmodel_smote = LogisticRegression(random_state=42, solver='liblinear')\nmodel_smote.fit(X_train_smote, y_train_smote)\n\n# Predict and evaluate\ny_pred_smote = model_smote.predict(X_valid)\nf1_smote = f1_score(y_valid, y_pred_smote)\n\nprint(\"F1-Score (SMOTE):\", f1_smote)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "The F1-score of 0.3402 with SMOTE (Synthetic Minority Over-sampling Technique) suggests that generating synthetic samples for the minority class did not significantly improve performance compared to previous approaches."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nYou have a mistake here. Becasue of additional data split X_train_over and X_train_under may intersect with X_valid. And that's not correct. You should not split the data here for the second time. Just use X_train from your previous split. You can upsample or downsample only train data and so you don't need to work with the full data here.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\">\n  Am I on the rack track here? Please refrain from additional comments below I know theres some correcting needed but wanted to confirm this was right before moving on. Thank you!"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\n1. You've already splitted the data into 3 parts above. What is the purpose to split tha data again here? It's not a good idea. Please, split the data only once in your project. Splitting the data several times is a direct way to make some mistakes.\n2. You've already filled all the NaNs above. You should not repeat this action here. Just remember a simple rule: any unique action should be done only once.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n\nPoint 1 is still not fixed. You should split the data only once but you did it a lot of times. Please, fix it. You already have such variables like X_train, X_valid, X_test, y_train, y_valid, y_test. Please, use them.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nYou have too good results here because your train and validation data have intersection due to the reason I described in the comment above.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n\nFixed\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n\nYou forgot to update/remove the text above.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V4</b> <a class=\"tocSkip\"></a>\n\nFixed\n\n</div>"}, {"cell_type": "code", "execution_count": 28, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Logistic Regression - F1 Score: 0.5176738882554162, ROC-AUC Score: 0.726861431339705\nRandom Forest (Tuned) - F1 Score (Validation): 0.6343042071197411, ROC-AUC Score (Validation): 0.7716852235031366\nRandom Forest (Tuned) - F1 Score (Test): 0.6314102564102564, ROC-AUC Score (Test): 0.7719047945675286\n"}], "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score\n\n\n# Calculate the scale_pos_weight\nscale_pos_weight_value = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n\n# Initialize Logistic Regression with class weight handling\nlogreg_model = LogisticRegression(\n    random_state=42,\n    solver='liblinear',  # Suitable for small datasets and imbalanced data\n    class_weight='balanced'  # Automatically adjusts weights based on class distribution\n)\n\n# Train the model on the scaled dataset\nlogreg_model.fit(X_train_scaled, y_train)\n\n# Predict on validation set\ny_pred_logreg = logreg_model.predict(X_valid_scaled)\n\n# Evaluate the model\nf1_logreg = f1_score(y_valid, y_pred_logreg)\nroc_auc_logreg = roc_auc_score(y_valid, y_pred_logreg)\n\n# Display final performance\nprint(f\"Logistic Regression - F1 Score: {f1_logreg}, ROC-AUC Score: {roc_auc_logreg}\")\n\n# Hyperparameter tuning for RandomForestClassifier using GridSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'class_weight': ['balanced']\n}\n\nrf_model = RandomForestClassifier(random_state=52)\n\ngrid_search = GridSearchCV(rf_model, param_grid, scoring='f1', cv=5, n_jobs=-1)\ngrid_search.fit(X_train_scaled, y_train)\n\n# Best model after tuning\nbest_rf_model = grid_search.best_estimator_\n\n# Predict on validation set\ny_pred_valid_rf = best_rf_model.predict(X_valid_scaled)\nf1_valid_rf = f1_score(y_valid, y_pred_valid_rf)\nroc_auc_valid_rf = roc_auc_score(y_valid, y_pred_valid_rf)\n\n# Predict on test set\ny_pred_test_rf = best_rf_model.predict(X_test_scaled)\nf1_test_rf = f1_score(y_test, y_pred_test_rf)\nroc_auc_test_rf = roc_auc_score(y_test, y_pred_test_rf)\n\n# Return the results\nprint(f\"Random Forest (Tuned) - F1 Score (Validation): {f1_valid_rf}, ROC-AUC Score (Validation): {roc_auc_valid_rf}\")\nprint(f\"Random Forest (Tuned) - F1 Score (Test): {f1_test_rf}, ROC-AUC Score (Test): {roc_auc_test_rf}\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "Logistic Regression Performance:\n\nF1 Score: 0.5177\nROC-AUC Score: 0.7269\nThe model demonstrates moderate predictive performance, with a decent ROC-AUC score indicating reasonable class separation.\n\nRandom Forest (Tuned) Performance:\n\nValidation Set:\n\nF1 Score: 0.6343\nROC-AUC Score: 0.7717\nThe model performs well on the validation set, showing strong discriminatory power and improved recall compared to logistic regression.\n\nTest Set:\n\nF1 Score: 0.6314\nROC-AUC Score: 0.7719\nThe model meets the F1-score requirement (\u2265 0.59) and maintains strong classification performance on the test set. The robust ROC-AUC score suggests reliable class separation across both validation and test data."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nUnfortunately, there is an issue here. From the lesson you know that only train data can be changed, right? But for happens when you put upsampled data into GridSearchCV? GridSearchCV has a built it cross validation and both train and validation data will be upsampled if you put upsampled data. In such case you will find the best hyperparameters not for initial task but for the changed one.\n    \nHow to deal with it? There are several options:\n    \n1. Do not use GridSearchCV or cross_val_score function to tune hyperparameters. Use a simple loop with a regular validation for it.\n2. Use library imblearn: https://imbalanced-learn.org/stable/. In this library there is a special pipeline which can deal with cross validation properly. But it's really difficult to install this library on our server. So, this the best solution but it can be done only locally.\n3. Instead of tuning hyperparameters on upsampled/downsampled data, tune hyperparameters on regular data but with class_weight='balanced'. In such case you can use GridSearchCV as usual.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\nDid you read my previous comment carefully? You can't use GridSearchCV with upsampled or downsampled data. I explained why in my previous comment. Read it carefully, please. To avoid this problem, use original data but use `class_weight='balanced'` parameter of the ML model.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n\nSomething is wrong with the quality on the validation data. It's not possible to have f1=0.16 validation and f1=0.61 on test data in the same time. It means you a have a problem with validation data. So, please, find the problem and fix it.\n    \nIf you look at grid_search.best_score_, you will see the correct value. You should get similar value in the variable f1_best_xgb.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V4</b> <a class=\"tocSkip\"></a>\n\n1. Not fixed. The metrics on validation and on test data are too different to be true. They should be similar. Not the same but similar. The reason is different preprocessing for different data parts. You forgot to scale validation data.\n2. Please, tune hyperparameters at least for one model with `class_weight='balanced'`.\n3. Choose only one the best model based on quality on validation data and test it on the test data below. F1 score on the test data should be not less than 0.59.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V5</b> <a class=\"tocSkip\"></a>\n\nDid you read my previous comment? Points 1 and 2 are still not fixed.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\">\nI may not understand what your asking me to do, I removed the class_weight='balanced' from random forest model in cell 30 and left it in cell 26, could you clarify because after removing the class_weight, I had increased the f1 score to 0.596"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V6</b> <a class=\"tocSkip\"></a>\n\nWhy did you remove class_weight='balanced'? I did not ask you to do it. Bring it back, please.\n    \nOkay, one more time:\n    \n1. Please, check the place where you scaled data. Do you see a code for scaling validation data? No. You did not scale validation data. You scaled only train and test data but not validation. This is not correct. And this is the reason why you got such bad results on validation data. So, please scale validation data.\n2. You need to tune hyperparameters for any model while working with imbalance. The easiest way is to tune hyperparameters for any model with class_weight='balanced' using GridSearchCV. Could you do, please?\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\">\n    Is this correct now?"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V7</b> <a class=\"tocSkip\"></a>\n\nHyperparameter tuning is correct.\n    \nBut scaling is still wrong. Please, check you code carefuly. You have done scaling in two places. Due to it you scaled train and test data twice but validation data is scaled only once. It means you still have different preprocessing for different data parts and thus you got wrong results on validation. Please, scale data only once but scale all 3 data parts: train, validation and test. Remove the second scaling the previous cell and fix the first scaling at the beginning of the project.\n    \nAs long as the model quality is very different between the test and validation data, it means that the bug is still not fixed. Please do not resubmit the project for re-checking until this problem is fixed.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\">\n    I believe I have it corrected now"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V7</b> <a class=\"tocSkip\"></a>\n\nYes. Now everything is correct. Well done!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V6</b> <a class=\"tocSkip\"></a>\n\nThis is not your best model. Please, choose the best model based on quality on validation data as a final one.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V7</b> <a class=\"tocSkip\"></a>\n\nNot fixed.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nYou have too good results here because your train and test data have intersection due to the reason I described in the comment above.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\nSomething is wrong here. F1 should be not less than 0.59 on the test data. This happened because you splitted the data 2 times in different places. Your X_test is scaled. But other data parts are not scaled because your overwrote the scaled data with unscaled data with the second split. This is why you should split the data only once in the project to avoid such mistakes.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n\nWell done!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "1. Project Conclusion\n\nThe dataset was successfully preprocessed to ensure data quality and consistency. Unnecessary columns were removed, categorical variables were encoded, missing values were handled appropriately, and numerical features were standardized. Additionally, a significant class imbalance was identified, with approximately 79.6% of customers staying and only 20.4% leaving, posing a challenge for predictive modeling.\n\n1.1 Baseline Model Performance\n\nA logistic regression model was trained without handling class imbalance to establish a benchmark. The results were:\n\nF1 Score: 0.5177\n\nROC-AUC Score: 0.7269\n\nThe model demonstrated moderate predictive performance, with a decent ROC-AUC score indicating reasonable class separation.\n\n1.2 Attempts to Improve Model Performance\n\nSeveral techniques were applied to enhance classification performance, including:\n\nClass Balancing (Oversampling, Undersampling, and SMOTE): These methods were tested but did not yield significant improvement beyond the baseline logistic regression.\n\nClass Weighting (class_weight='balanced'): Adjusting class weights did not lead to meaningful gains in classification performance.\n\nFeature Engineering & Hyperparameter Tuning: These approaches were explored to enhance model performance further.\n\n1.3 Final Model Selection and Performance\n\nA Random Forest model was trained and optimized using hyperparameter tuning. The best model, selected based on validation performance, achieved the following results:\n\nValidation Set:\nF1 Score: 0.6343\n\nROC-AUC Score: 0.7717\n\nThe model performed well on the validation set, demonstrating strong discriminatory power and improved recall compared to logistic regression.\n\nTest Set:\n\nF1 Score: 0.6314\n\nROC-AUC Score: 0.7719\n\nThe model successfully met the required F1-score threshold (\u2265 0.59) and maintained strong classification performance on the test set. The robust ROC-AUC score suggests reliable class separation across both validation and test data.\n\n1.4 Conclusion\n\nLogistic regression, despite achieving moderate performance, did not outperform the Random Forest model. The tuned Random Forest model successfully met the required F1-score threshold of 0.59 on the test set, demonstrating reliable classification performance.\n\nFuture improvements could include:\n\nAdvanced feature engineering to enhance predictive power.\nExploring deep learning models or gradient boosting techniques for potential performance gains.\nEnsuring consistent preprocessing across all data splits to minimize discrepancies and improve model generalization."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V3</b> <a class=\"tocSkip\"></a>\n\nYou forgot to update all the text above.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\">\n    Should be completed now :)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V4</b> <a class=\"tocSkip\"></a>\n\n1. The results in the parts \"4.3.1  Validation Results:\" and \"4.3.1  Validation Results:\" are not true. \n2. \"F1 Score: 0.59 (met project requirement)\" - I don't see such result. I see 0.589 but it is less than 0.59\n3. \"4.3  4.3 XGBoost Model (Tuned)\" - I don't see this part in your project\n\n</div>"}], "metadata": {"ExecuteTimeLog": [{"duration": 303, "start_time": "2025-03-04T19:26:22.618Z"}, {"duration": 20, "start_time": "2025-03-04T19:28:19.169Z"}, {"duration": 14, "start_time": "2025-03-04T19:28:25.530Z"}, {"duration": 196, "start_time": "2025-03-04T19:31:36.082Z"}, {"duration": 442, "start_time": "2025-03-04T19:31:44.190Z"}, {"duration": 16, "start_time": "2025-03-04T19:31:44.634Z"}, {"duration": 10, "start_time": "2025-03-04T19:31:44.652Z"}, {"duration": 88, "start_time": "2025-03-04T19:31:44.665Z"}, {"duration": 711, "start_time": "2025-03-04T19:34:37.432Z"}, {"duration": 35, "start_time": "2025-03-04T19:35:48.487Z"}, {"duration": 13, "start_time": "2025-03-04T19:36:34.385Z"}, {"duration": 36, "start_time": "2025-03-04T19:37:06.546Z"}, {"duration": 4, "start_time": "2025-03-04T19:39:38.767Z"}, {"duration": 9, "start_time": "2025-03-04T19:39:49.987Z"}, {"duration": 3, "start_time": "2025-03-04T19:41:07.819Z"}, {"duration": 4, "start_time": "2025-03-04T19:41:26.567Z"}, {"duration": 188, "start_time": "2025-03-04T19:41:54.020Z"}, {"duration": 3, "start_time": "2025-03-04T19:42:58.951Z"}, {"duration": 10, "start_time": "2025-03-04T19:43:12.764Z"}, {"duration": 2007, "start_time": "2025-03-04T19:43:55.449Z"}, {"duration": 17, "start_time": "2025-03-04T19:43:57.458Z"}, {"duration": 10, "start_time": "2025-03-04T19:43:57.478Z"}, {"duration": 3, "start_time": "2025-03-04T19:43:57.490Z"}, {"duration": 9, "start_time": "2025-03-04T19:43:57.497Z"}, {"duration": 25, "start_time": "2025-03-04T19:43:57.508Z"}, {"duration": 10, "start_time": "2025-03-04T19:43:57.535Z"}, {"duration": 5, "start_time": "2025-03-04T19:43:57.547Z"}, {"duration": 4, "start_time": "2025-03-04T19:43:57.554Z"}, {"duration": 28, "start_time": "2025-03-04T19:43:57.560Z"}, {"duration": 3, "start_time": "2025-03-04T19:45:46.684Z"}, {"duration": 54, "start_time": "2025-03-04T19:45:57.856Z"}, {"duration": 5, "start_time": "2025-03-04T19:46:36.589Z"}, {"duration": 14, "start_time": "2025-03-04T19:46:48.376Z"}, {"duration": 37, "start_time": "2025-03-04T19:47:15.989Z"}, {"duration": 42, "start_time": "2025-03-04T19:48:37.539Z"}, {"duration": 41, "start_time": "2025-03-04T19:48:58.505Z"}, {"duration": 3, "start_time": "2025-03-04T19:51:37.963Z"}, {"duration": 3, "start_time": "2025-03-04T19:51:52.897Z"}, {"duration": 3, "start_time": "2025-03-04T19:51:56.173Z"}, {"duration": 14, "start_time": "2025-03-04T19:51:56.179Z"}, {"duration": 10, "start_time": "2025-03-04T19:51:56.195Z"}, {"duration": 4, "start_time": "2025-03-04T19:51:56.207Z"}, {"duration": 9, "start_time": "2025-03-04T19:51:56.213Z"}, {"duration": 4, "start_time": "2025-03-04T19:51:56.223Z"}, {"duration": 3, "start_time": "2025-03-04T19:51:56.229Z"}, {"duration": 10, "start_time": "2025-03-04T19:51:56.234Z"}, {"duration": 4, "start_time": "2025-03-04T19:51:56.246Z"}, {"duration": 4, "start_time": "2025-03-04T19:51:56.251Z"}, {"duration": 25, "start_time": "2025-03-04T19:51:56.257Z"}, {"duration": 121, "start_time": "2025-03-04T19:54:18.835Z"}, {"duration": 34, "start_time": "2025-03-04T19:56:34.116Z"}, {"duration": 99, "start_time": "2025-03-04T19:57:21.547Z"}, {"duration": 3343, "start_time": "2025-03-04T19:58:53.937Z"}, {"duration": 391258, "start_time": "2025-03-04T20:00:03.005Z"}, {"duration": 18, "start_time": "2025-03-04T20:13:33.156Z"}, {"duration": 8, "start_time": "2025-03-04T20:15:38.830Z"}, {"duration": 2670, "start_time": "2025-03-06T19:06:25.647Z"}, {"duration": 20, "start_time": "2025-03-06T19:06:28.320Z"}, {"duration": 12, "start_time": "2025-03-06T19:06:28.343Z"}, {"duration": 3, "start_time": "2025-03-06T19:06:28.357Z"}, {"duration": 10, "start_time": "2025-03-06T19:06:28.363Z"}, {"duration": 4, "start_time": "2025-03-06T19:06:28.374Z"}, {"duration": 3, "start_time": "2025-03-06T19:06:28.380Z"}, {"duration": 35, "start_time": "2025-03-06T19:06:28.384Z"}, {"duration": 5, "start_time": "2025-03-06T19:06:28.420Z"}, {"duration": 4, "start_time": "2025-03-06T19:06:28.426Z"}, {"duration": 891, "start_time": "2025-03-06T19:06:28.431Z"}, {"duration": 0, "start_time": "2025-03-06T19:06:29.324Z"}, {"duration": 0, "start_time": "2025-03-06T19:06:29.325Z"}, {"duration": 0, "start_time": "2025-03-06T19:06:29.327Z"}, {"duration": 0, "start_time": "2025-03-06T19:06:29.328Z"}, {"duration": 0, "start_time": "2025-03-06T19:06:29.329Z"}, {"duration": 0, "start_time": "2025-03-06T19:06:29.330Z"}, {"duration": 285, "start_time": "2025-03-06T19:07:50.248Z"}, {"duration": 68, "start_time": "2025-03-06T19:10:55.395Z"}, {"duration": 12, "start_time": "2025-03-06T19:11:17.428Z"}, {"duration": 15, "start_time": "2025-03-06T19:11:23.943Z"}, {"duration": 13, "start_time": "2025-03-06T19:11:35.884Z"}, {"duration": 12, "start_time": "2025-03-06T19:12:43.058Z"}, {"duration": 6, "start_time": "2025-03-06T19:13:20.464Z"}, {"duration": 3, "start_time": "2025-03-06T19:13:58.406Z"}, {"duration": 20, "start_time": "2025-03-06T19:13:58.416Z"}, {"duration": 14, "start_time": "2025-03-06T19:13:58.438Z"}, {"duration": 3, "start_time": "2025-03-06T19:13:58.454Z"}, {"duration": 10, "start_time": "2025-03-06T19:13:58.459Z"}, {"duration": 4, "start_time": "2025-03-06T19:13:58.472Z"}, {"duration": 4, "start_time": "2025-03-06T19:13:58.478Z"}, {"duration": 36, "start_time": "2025-03-06T19:13:58.483Z"}, {"duration": 4, "start_time": "2025-03-06T19:13:58.520Z"}, {"duration": 4, "start_time": "2025-03-06T19:13:58.526Z"}, {"duration": 4, "start_time": "2025-03-06T19:13:58.531Z"}, {"duration": 34, "start_time": "2025-03-06T19:13:58.537Z"}, {"duration": 150, "start_time": "2025-03-06T19:13:58.574Z"}, {"duration": 95, "start_time": "2025-03-06T19:13:58.727Z"}, {"duration": 515, "start_time": "2025-03-06T19:13:58.825Z"}, {"duration": 94414, "start_time": "2025-03-06T19:13:59.348Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.778Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.813Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.815Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.817Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.819Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.824Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.826Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.828Z"}, {"duration": 1, "start_time": "2025-03-06T19:27:40.830Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.832Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.836Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.838Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.840Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.842Z"}, {"duration": 1, "start_time": "2025-03-06T19:27:40.843Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.844Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.845Z"}, {"duration": 0, "start_time": "2025-03-06T19:27:40.846Z"}, {"duration": 2687, "start_time": "2025-03-08T19:10:14.221Z"}, {"duration": 27, "start_time": "2025-03-08T19:10:19.416Z"}, {"duration": 14, "start_time": "2025-03-08T19:10:21.088Z"}, {"duration": 5, "start_time": "2025-03-08T19:10:25.626Z"}, {"duration": 10, "start_time": "2025-03-08T19:10:27.299Z"}, {"duration": 4, "start_time": "2025-03-08T19:10:30.570Z"}, {"duration": 5, "start_time": "2025-03-08T19:10:33.120Z"}, {"duration": 10, "start_time": "2025-03-08T19:10:35.817Z"}, {"duration": 4, "start_time": "2025-03-08T19:10:40.095Z"}, {"duration": 4, "start_time": "2025-03-08T19:10:43.726Z"}, {"duration": 5, "start_time": "2025-03-08T19:10:46.421Z"}, {"duration": 4, "start_time": "2025-03-08T19:11:12.355Z"}, {"duration": 8, "start_time": "2025-03-08T19:11:39.749Z"}, {"duration": 4, "start_time": "2025-03-08T19:11:58.381Z"}, {"duration": 4, "start_time": "2025-03-08T19:12:13.066Z"}, {"duration": 9, "start_time": "2025-03-08T19:12:57.977Z"}, {"duration": 33, "start_time": "2025-03-08T19:13:05.858Z"}, {"duration": 132, "start_time": "2025-03-08T19:13:32.952Z"}, {"duration": 31, "start_time": "2025-03-08T19:13:45.024Z"}, {"duration": 366, "start_time": "2025-03-08T19:19:33.445Z"}, {"duration": 165, "start_time": "2025-03-10T01:40:32.246Z"}, {"duration": 2847, "start_time": "2025-03-10T01:40:36.766Z"}, {"duration": 20, "start_time": "2025-03-10T01:40:39.615Z"}, {"duration": 13, "start_time": "2025-03-10T01:40:39.637Z"}, {"duration": 4, "start_time": "2025-03-10T01:40:39.652Z"}, {"duration": 90, "start_time": "2025-03-10T01:40:39.657Z"}, {"duration": 4, "start_time": "2025-03-10T01:40:39.749Z"}, {"duration": 7, "start_time": "2025-03-10T01:40:39.755Z"}, {"duration": 12, "start_time": "2025-03-10T01:40:39.764Z"}, {"duration": 7, "start_time": "2025-03-10T01:40:39.779Z"}, {"duration": 4, "start_time": "2025-03-10T01:40:39.811Z"}, {"duration": 4, "start_time": "2025-03-10T01:40:39.817Z"}, {"duration": 4, "start_time": "2025-03-10T01:40:39.824Z"}, {"duration": 9, "start_time": "2025-03-10T01:40:39.829Z"}, {"duration": 5, "start_time": "2025-03-10T01:40:39.841Z"}, {"duration": 5, "start_time": "2025-03-10T01:40:39.848Z"}, {"duration": 8, "start_time": "2025-03-10T01:40:39.855Z"}, {"duration": 60, "start_time": "2025-03-10T01:40:39.865Z"}, {"duration": 128, "start_time": "2025-03-10T01:40:39.927Z"}, {"duration": 61, "start_time": "2025-03-10T01:40:40.057Z"}, {"duration": 388, "start_time": "2025-03-10T01:40:40.121Z"}, {"duration": 3115, "start_time": "2025-03-10T01:40:40.515Z"}, {"duration": 279983, "start_time": "2025-03-10T01:40:43.632Z"}, {"duration": 12, "start_time": "2025-03-10T01:45:23.618Z"}, {"duration": 162, "start_time": "2025-03-13T15:53:43.934Z"}, {"duration": 2664, "start_time": "2025-03-13T15:53:50.214Z"}, {"duration": 28, "start_time": "2025-03-13T15:53:52.880Z"}, {"duration": 13, "start_time": "2025-03-13T15:53:52.909Z"}, {"duration": 3, "start_time": "2025-03-13T15:53:52.923Z"}, {"duration": 62, "start_time": "2025-03-13T15:53:52.929Z"}, {"duration": 4, "start_time": "2025-03-13T15:53:52.993Z"}, {"duration": 4, "start_time": "2025-03-13T15:53:53.011Z"}, {"duration": 9, "start_time": "2025-03-13T15:53:53.016Z"}, {"duration": 4, "start_time": "2025-03-13T15:53:53.027Z"}, {"duration": 5, "start_time": "2025-03-13T15:53:53.032Z"}, {"duration": 4, "start_time": "2025-03-13T15:53:53.038Z"}, {"duration": 5, "start_time": "2025-03-13T15:53:53.044Z"}, {"duration": 7, "start_time": "2025-03-13T15:53:53.050Z"}, {"duration": 4, "start_time": "2025-03-13T15:53:53.060Z"}, {"duration": 4, "start_time": "2025-03-13T15:53:53.066Z"}, {"duration": 48, "start_time": "2025-03-13T15:53:53.072Z"}, {"duration": 21, "start_time": "2025-03-13T15:53:53.121Z"}, {"duration": 148, "start_time": "2025-03-13T15:53:53.145Z"}, {"duration": 32, "start_time": "2025-03-13T15:53:53.294Z"}, {"duration": 199, "start_time": "2025-03-13T15:53:53.329Z"}, {"duration": 3189, "start_time": "2025-03-13T15:53:53.529Z"}, {"duration": 272712, "start_time": "2025-03-13T15:53:56.719Z"}, {"duration": 17, "start_time": "2025-03-13T15:58:29.432Z"}, {"duration": 108, "start_time": "2025-03-13T16:17:01.011Z"}, {"duration": 90, "start_time": "2025-03-13T16:37:25.735Z"}, {"duration": 35, "start_time": "2025-03-13T16:37:35.671Z"}, {"duration": 4, "start_time": "2025-03-13T16:38:09.700Z"}, {"duration": 26, "start_time": "2025-03-13T16:38:19.073Z"}, {"duration": 67, "start_time": "2025-03-13T16:40:41.400Z"}, {"duration": 3, "start_time": "2025-03-13T16:41:17.409Z"}, {"duration": 15, "start_time": "2025-03-13T16:41:17.414Z"}, {"duration": 10, "start_time": "2025-03-13T16:41:17.431Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.443Z"}, {"duration": 9, "start_time": "2025-03-13T16:41:17.448Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.459Z"}, {"duration": 3, "start_time": "2025-03-13T16:41:17.464Z"}, {"duration": 44, "start_time": "2025-03-13T16:41:17.469Z"}, {"duration": 5, "start_time": "2025-03-13T16:41:17.514Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.521Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.526Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.532Z"}, {"duration": 7, "start_time": "2025-03-13T16:41:17.537Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.545Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:17.550Z"}, {"duration": 8, "start_time": "2025-03-13T16:41:17.555Z"}, {"duration": 63, "start_time": "2025-03-13T16:41:17.565Z"}, {"duration": 107, "start_time": "2025-03-13T16:41:17.629Z"}, {"duration": 75, "start_time": "2025-03-13T16:41:17.738Z"}, {"duration": 144, "start_time": "2025-03-13T16:41:17.817Z"}, {"duration": 72, "start_time": "2025-03-13T16:41:17.964Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:19.825Z"}, {"duration": 14, "start_time": "2025-03-13T16:41:19.831Z"}, {"duration": 9, "start_time": "2025-03-13T16:41:19.847Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:19.858Z"}, {"duration": 8, "start_time": "2025-03-13T16:41:19.865Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:19.875Z"}, {"duration": 32, "start_time": "2025-03-13T16:41:19.880Z"}, {"duration": 8, "start_time": "2025-03-13T16:41:19.914Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:19.923Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:19.929Z"}, {"duration": 4, "start_time": "2025-03-13T16:41:19.934Z"}, {"duration": 5, "start_time": "2025-03-13T16:41:19.939Z"}, {"duration": 8, "start_time": "2025-03-13T16:41:19.946Z"}, {"duration": 3, "start_time": "2025-03-13T16:41:19.958Z"}, {"duration": 7, "start_time": "2025-03-13T16:41:19.963Z"}, {"duration": 41, "start_time": "2025-03-13T16:41:19.972Z"}, {"duration": 22, "start_time": "2025-03-13T16:41:20.015Z"}, {"duration": 112, "start_time": "2025-03-13T16:41:20.039Z"}, {"duration": 63, "start_time": "2025-03-13T16:41:20.153Z"}, {"duration": 146, "start_time": "2025-03-13T16:41:20.218Z"}, {"duration": 66, "start_time": "2025-03-13T16:41:20.366Z"}, {"duration": 3182, "start_time": "2025-03-13T16:41:20.434Z"}, {"duration": 3, "start_time": "2025-03-13T16:46:29.967Z"}, {"duration": 47, "start_time": "2025-03-13T16:46:29.973Z"}, {"duration": 10, "start_time": "2025-03-13T16:46:30.022Z"}, {"duration": 4, "start_time": "2025-03-13T16:46:30.033Z"}, {"duration": 10, "start_time": "2025-03-13T16:46:30.039Z"}, {"duration": 3, "start_time": "2025-03-13T16:46:30.051Z"}, {"duration": 4, "start_time": "2025-03-13T16:46:30.056Z"}, {"duration": 10, "start_time": "2025-03-13T16:46:30.061Z"}, {"duration": 41, "start_time": "2025-03-13T16:46:30.072Z"}, {"duration": 5, "start_time": "2025-03-13T16:46:30.115Z"}, {"duration": 4, "start_time": "2025-03-13T16:46:30.121Z"}, {"duration": 5, "start_time": "2025-03-13T16:46:30.127Z"}, {"duration": 7, "start_time": "2025-03-13T16:46:30.133Z"}, {"duration": 4, "start_time": "2025-03-13T16:46:30.141Z"}, {"duration": 4, "start_time": "2025-03-13T16:46:30.147Z"}, {"duration": 9, "start_time": "2025-03-13T16:46:30.152Z"}, {"duration": 68, "start_time": "2025-03-13T16:46:30.162Z"}, {"duration": 109, "start_time": "2025-03-13T16:46:30.232Z"}, {"duration": 22, "start_time": "2025-03-13T16:46:30.343Z"}, {"duration": 133, "start_time": "2025-03-13T16:46:30.412Z"}, {"duration": 75, "start_time": "2025-03-13T16:46:30.547Z"}, {"duration": 3491, "start_time": "2025-03-13T16:46:30.624Z"}, {"duration": 5194, "start_time": "2025-03-13T16:46:34.119Z"}, {"duration": 98, "start_time": "2025-03-13T16:46:39.314Z"}, {"duration": 231, "start_time": "2025-03-13T19:03:43.230Z"}, {"duration": 3306, "start_time": "2025-03-13T19:04:06.088Z"}, {"duration": 23, "start_time": "2025-03-13T19:04:09.397Z"}, {"duration": 13, "start_time": "2025-03-13T19:04:09.426Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:09.441Z"}, {"duration": 85, "start_time": "2025-03-13T19:04:09.449Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:09.536Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:09.543Z"}, {"duration": 11, "start_time": "2025-03-13T19:04:09.549Z"}, {"duration": 13, "start_time": "2025-03-13T19:04:09.561Z"}, {"duration": 5, "start_time": "2025-03-13T19:04:09.576Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:09.583Z"}, {"duration": 33, "start_time": "2025-03-13T19:04:09.591Z"}, {"duration": 9, "start_time": "2025-03-13T19:04:09.627Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:09.641Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:09.647Z"}, {"duration": 9, "start_time": "2025-03-13T19:04:09.654Z"}, {"duration": 32, "start_time": "2025-03-13T19:04:09.665Z"}, {"duration": 173, "start_time": "2025-03-13T19:04:09.700Z"}, {"duration": 77, "start_time": "2025-03-13T19:04:09.875Z"}, {"duration": 133, "start_time": "2025-03-13T19:04:09.956Z"}, {"duration": 149, "start_time": "2025-03-13T19:04:10.094Z"}, {"duration": 165, "start_time": "2025-03-13T19:04:10.245Z"}, {"duration": 0, "start_time": "2025-03-13T19:04:10.426Z"}, {"duration": 0, "start_time": "2025-03-13T19:04:10.427Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.730Z"}, {"duration": 19, "start_time": "2025-03-13T19:04:40.736Z"}, {"duration": 12, "start_time": "2025-03-13T19:04:40.759Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.818Z"}, {"duration": 12, "start_time": "2025-03-13T19:04:40.825Z"}, {"duration": 6, "start_time": "2025-03-13T19:04:40.840Z"}, {"duration": 6, "start_time": "2025-03-13T19:04:40.848Z"}, {"duration": 10, "start_time": "2025-03-13T19:04:40.857Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.869Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.875Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.881Z"}, {"duration": 6, "start_time": "2025-03-13T19:04:40.886Z"}, {"duration": 6, "start_time": "2025-03-13T19:04:40.894Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.924Z"}, {"duration": 4, "start_time": "2025-03-13T19:04:40.930Z"}, {"duration": 10, "start_time": "2025-03-13T19:04:40.936Z"}, {"duration": 29, "start_time": "2025-03-13T19:04:40.949Z"}, {"duration": 158, "start_time": "2025-03-13T19:04:40.980Z"}, {"duration": 189, "start_time": "2025-03-13T19:04:41.140Z"}, {"duration": 198, "start_time": "2025-03-13T19:04:41.330Z"}, {"duration": 102, "start_time": "2025-03-13T19:04:41.532Z"}, {"duration": 2900, "start_time": "2025-03-13T19:36:31.699Z"}, {"duration": 21, "start_time": "2025-03-13T19:36:34.714Z"}, {"duration": 15, "start_time": "2025-03-13T19:36:35.364Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:35.868Z"}, {"duration": 11, "start_time": "2025-03-13T19:36:35.943Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:36.029Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:36.108Z"}, {"duration": 9, "start_time": "2025-03-13T19:36:36.209Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:36.275Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:36.361Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:36.444Z"}, {"duration": 5, "start_time": "2025-03-13T19:36:36.524Z"}, {"duration": 8, "start_time": "2025-03-13T19:36:36.607Z"}, {"duration": 4, "start_time": "2025-03-13T19:36:36.690Z"}, {"duration": 5, "start_time": "2025-03-13T19:36:36.777Z"}, {"duration": 8, "start_time": "2025-03-13T19:36:36.860Z"}, {"duration": 29, "start_time": "2025-03-13T19:36:36.944Z"}, {"duration": 117, "start_time": "2025-03-13T19:36:37.363Z"}, {"duration": 24, "start_time": "2025-03-13T19:36:37.614Z"}, {"duration": 126, "start_time": "2025-03-13T19:36:37.864Z"}, {"duration": 117, "start_time": "2025-03-13T19:36:37.992Z"}, {"duration": 454841, "start_time": "2025-03-13T19:36:38.531Z"}, {"duration": 43, "start_time": "2025-03-13T19:44:13.375Z"}, {"duration": 3, "start_time": "2025-03-13T19:50:22.993Z"}, {"duration": 67, "start_time": "2025-03-13T19:51:09.424Z"}, {"duration": 6, "start_time": "2025-03-13T19:52:14.133Z"}, {"duration": 4, "start_time": "2025-03-13T19:52:54.174Z"}, {"duration": 4, "start_time": "2025-03-13T19:52:58.457Z"}, {"duration": 2735, "start_time": "2025-03-14T16:58:27.903Z"}, {"duration": 30, "start_time": "2025-03-14T16:58:30.640Z"}, {"duration": 13, "start_time": "2025-03-14T16:58:30.671Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.687Z"}, {"duration": 10, "start_time": "2025-03-14T16:58:30.692Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.709Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.715Z"}, {"duration": 9, "start_time": "2025-03-14T16:58:30.720Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.731Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.737Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.743Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.748Z"}, {"duration": 7, "start_time": "2025-03-14T16:58:30.754Z"}, {"duration": 4, "start_time": "2025-03-14T16:58:30.762Z"}, {"duration": 45, "start_time": "2025-03-14T16:58:30.767Z"}, {"duration": 8, "start_time": "2025-03-14T16:58:30.814Z"}, {"duration": 23, "start_time": "2025-03-14T16:58:30.824Z"}, {"duration": 139, "start_time": "2025-03-14T16:58:30.848Z"}, {"duration": 36, "start_time": "2025-03-14T16:58:30.989Z"}, {"duration": 406, "start_time": "2025-03-14T16:58:31.027Z"}, {"duration": 0, "start_time": "2025-03-14T16:58:31.436Z"}, {"duration": 0, "start_time": "2025-03-14T16:58:31.437Z"}, {"duration": 0, "start_time": "2025-03-14T16:58:31.439Z"}, {"duration": 24, "start_time": "2025-03-14T17:00:50.662Z"}, {"duration": 26, "start_time": "2025-03-14T17:03:45.656Z"}, {"duration": 19, "start_time": "2025-03-14T17:06:25.329Z"}, {"duration": 16, "start_time": "2025-03-14T17:07:28.170Z"}, {"duration": 408125, "start_time": "2025-03-14T17:08:01.508Z"}, {"duration": 19, "start_time": "2025-03-14T17:36:40.689Z"}, {"duration": 20, "start_time": "2025-03-14T17:36:46.287Z"}, {"duration": 25, "start_time": "2025-03-14T17:50:51.982Z"}, {"duration": 25, "start_time": "2025-03-14T18:01:40.842Z"}, {"duration": 29, "start_time": "2025-03-14T18:02:59.937Z"}, {"duration": 9828, "start_time": "2025-03-14T18:05:51.524Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.356Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.357Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.358Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.360Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.361Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.362Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.363Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.364Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.365Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.366Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.367Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.369Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.371Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.372Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.373Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.375Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.376Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.377Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.379Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.380Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.381Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.383Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.384Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:01.385Z"}, {"duration": 1488, "start_time": "2025-03-14T18:06:07.291Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.783Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.784Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.785Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.787Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.789Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.790Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.792Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.793Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.795Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.796Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.798Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.799Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.801Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.802Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.804Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.805Z"}, {"duration": 1, "start_time": "2025-03-14T18:06:08.806Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.808Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.809Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.811Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.812Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.814Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.815Z"}, {"duration": 0, "start_time": "2025-03-14T18:06:08.817Z"}, {"duration": 1397, "start_time": "2025-03-14T18:07:23.097Z"}, {"duration": 31, "start_time": "2025-03-14T18:07:34.393Z"}, {"duration": 1474, "start_time": "2025-03-14T18:11:58.178Z"}, {"duration": 24, "start_time": "2025-03-14T18:11:59.655Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.682Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.683Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.684Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.685Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.687Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.688Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.689Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.691Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.692Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.694Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.695Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.697Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.698Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.699Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.700Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.701Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.703Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.704Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.705Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.706Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.707Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.709Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.710Z"}, {"duration": 0, "start_time": "2025-03-14T18:11:59.715Z"}, {"duration": 1413, "start_time": "2025-03-14T18:14:34.707Z"}, {"duration": 29, "start_time": "2025-03-14T18:14:36.123Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.154Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.156Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.157Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.158Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.159Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.160Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.162Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.163Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.164Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.165Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.166Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.167Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.169Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.171Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.172Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.173Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.174Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.175Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.177Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.177Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.178Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.179Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.180Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.181Z"}, {"duration": 0, "start_time": "2025-03-14T18:14:36.182Z"}, {"duration": 792, "start_time": "2025-03-14T18:16:34.086Z"}, {"duration": 807, "start_time": "2025-03-14T18:16:57.582Z"}, {"duration": 4134, "start_time": "2025-03-15T18:31:16.382Z"}, {"duration": 1849, "start_time": "2025-03-15T18:31:30.646Z"}, {"duration": 764, "start_time": "2025-03-15T18:31:32.498Z"}, {"duration": 2120, "start_time": "2025-03-15T18:31:33.264Z"}, {"duration": 28, "start_time": "2025-03-15T18:31:35.386Z"}, {"duration": 15, "start_time": "2025-03-15T18:31:35.417Z"}, {"duration": 5, "start_time": "2025-03-15T18:31:35.433Z"}, {"duration": 11, "start_time": "2025-03-15T18:31:35.440Z"}, {"duration": 6, "start_time": "2025-03-15T18:31:35.453Z"}, {"duration": 3, "start_time": "2025-03-15T18:31:35.461Z"}, {"duration": 9, "start_time": "2025-03-15T18:31:35.466Z"}, {"duration": 38, "start_time": "2025-03-15T18:31:35.477Z"}, {"duration": 5, "start_time": "2025-03-15T18:31:35.517Z"}, {"duration": 4, "start_time": "2025-03-15T18:31:35.524Z"}, {"duration": 4, "start_time": "2025-03-15T18:31:35.532Z"}, {"duration": 7, "start_time": "2025-03-15T18:31:35.538Z"}, {"duration": 4, "start_time": "2025-03-15T18:31:35.547Z"}, {"duration": 4, "start_time": "2025-03-15T18:31:35.553Z"}, {"duration": 10, "start_time": "2025-03-15T18:31:35.558Z"}, {"duration": 23, "start_time": "2025-03-15T18:31:35.611Z"}, {"duration": 138, "start_time": "2025-03-15T18:31:35.636Z"}, {"duration": 47, "start_time": "2025-03-15T18:31:35.776Z"}, {"duration": 99, "start_time": "2025-03-15T18:31:35.825Z"}, {"duration": 109, "start_time": "2025-03-15T18:31:35.926Z"}, {"duration": 90, "start_time": "2025-03-15T18:31:36.037Z"}, {"duration": 184, "start_time": "2025-03-15T18:31:36.130Z"}, {"duration": 102, "start_time": "2025-03-15T18:31:36.319Z"}, {"duration": 406, "start_time": "2025-03-15T18:31:36.426Z"}, {"duration": 14, "start_time": "2025-03-15T18:34:12.075Z"}, {"duration": 752, "start_time": "2025-03-15T18:44:46.760Z"}, {"duration": 296458, "start_time": "2025-03-15T18:46:46.023Z"}, {"duration": 746, "start_time": "2025-03-15T18:51:49.536Z"}, {"duration": 741, "start_time": "2025-03-15T18:51:59.317Z"}, {"duration": 735, "start_time": "2025-03-15T18:52:07.990Z"}, {"duration": 744, "start_time": "2025-03-15T18:52:16.211Z"}, {"duration": 741, "start_time": "2025-03-15T18:52:25.641Z"}, {"duration": 756, "start_time": "2025-03-15T18:52:34.034Z"}, {"duration": 923, "start_time": "2025-03-16T23:00:11.816Z"}, {"duration": 4126, "start_time": "2025-03-16T23:00:24.426Z"}, {"duration": 17, "start_time": "2025-03-16T23:00:28.554Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.574Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.575Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.577Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.578Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.579Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.580Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.581Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.582Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.583Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.584Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.585Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.587Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.588Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.589Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.590Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.591Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.593Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.595Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.596Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.597Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.598Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.599Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.600Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.601Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.602Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.603Z"}, {"duration": 0, "start_time": "2025-03-16T23:00:28.605Z"}, {"duration": 17, "start_time": "2025-03-16T23:00:57.232Z"}, {"duration": 2095, "start_time": "2025-03-16T23:01:37.207Z"}, {"duration": 1869, "start_time": "2025-03-16T23:01:45.519Z"}, {"duration": 762, "start_time": "2025-03-16T23:01:47.390Z"}, {"duration": 2015, "start_time": "2025-03-16T23:01:48.154Z"}, {"duration": 20, "start_time": "2025-03-16T23:01:50.172Z"}, {"duration": 12, "start_time": "2025-03-16T23:01:50.193Z"}, {"duration": 3, "start_time": "2025-03-16T23:01:50.207Z"}, {"duration": 10, "start_time": "2025-03-16T23:01:50.212Z"}, {"duration": 4, "start_time": "2025-03-16T23:01:50.223Z"}, {"duration": 3, "start_time": "2025-03-16T23:01:50.229Z"}, {"duration": 9, "start_time": "2025-03-16T23:01:50.236Z"}, {"duration": 40, "start_time": "2025-03-16T23:01:50.247Z"}, {"duration": 4, "start_time": "2025-03-16T23:01:50.288Z"}, {"duration": 4, "start_time": "2025-03-16T23:01:50.293Z"}, {"duration": 4, "start_time": "2025-03-16T23:01:50.299Z"}, {"duration": 8, "start_time": "2025-03-16T23:01:50.305Z"}, {"duration": 4, "start_time": "2025-03-16T23:01:50.314Z"}, {"duration": 4, "start_time": "2025-03-16T23:01:50.319Z"}, {"duration": 9, "start_time": "2025-03-16T23:01:50.324Z"}, {"duration": 63, "start_time": "2025-03-16T23:01:50.334Z"}, {"duration": 118, "start_time": "2025-03-16T23:01:50.398Z"}, {"duration": 69, "start_time": "2025-03-16T23:01:50.519Z"}, {"duration": 97, "start_time": "2025-03-16T23:01:50.590Z"}, {"duration": 106, "start_time": "2025-03-16T23:01:50.689Z"}, {"duration": 93, "start_time": "2025-03-16T23:01:50.797Z"}, {"duration": 126, "start_time": "2025-03-16T23:01:50.892Z"}, {"duration": 80, "start_time": "2025-03-16T23:01:51.020Z"}, {"duration": 26987, "start_time": "2025-03-16T23:01:51.102Z"}, {"duration": 823, "start_time": "2025-03-16T23:02:18.094Z"}, {"duration": 14, "start_time": "2025-03-16T23:02:18.919Z"}, {"duration": 762, "start_time": "2025-03-16T23:04:49.012Z"}, {"duration": 4016, "start_time": "2025-03-17T19:01:40.722Z"}, {"duration": 154, "start_time": "2025-03-17T19:01:44.740Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.897Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.899Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.900Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.912Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.913Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.915Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.916Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.917Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.918Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.919Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.921Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.922Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.923Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.925Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.927Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.928Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.929Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.931Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.933Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.934Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.935Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.936Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.938Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.940Z"}, {"duration": 0, "start_time": "2025-03-17T19:01:44.942Z"}, {"duration": 1807, "start_time": "2025-03-17T19:02:00.905Z"}, {"duration": 776, "start_time": "2025-03-17T19:02:02.715Z"}, {"duration": 2091, "start_time": "2025-03-17T19:02:03.493Z"}, {"duration": 22, "start_time": "2025-03-17T19:02:05.586Z"}, {"duration": 12, "start_time": "2025-03-17T19:02:05.611Z"}, {"duration": 3, "start_time": "2025-03-17T19:02:05.625Z"}, {"duration": 9, "start_time": "2025-03-17T19:02:05.630Z"}, {"duration": 3, "start_time": "2025-03-17T19:02:05.641Z"}, {"duration": 3, "start_time": "2025-03-17T19:02:05.646Z"}, {"duration": 10, "start_time": "2025-03-17T19:02:05.651Z"}, {"duration": 5, "start_time": "2025-03-17T19:02:05.662Z"}, {"duration": 4, "start_time": "2025-03-17T19:02:05.668Z"}, {"duration": 4, "start_time": "2025-03-17T19:02:05.712Z"}, {"duration": 4, "start_time": "2025-03-17T19:02:05.720Z"}, {"duration": 8, "start_time": "2025-03-17T19:02:05.726Z"}, {"duration": 3, "start_time": "2025-03-17T19:02:05.735Z"}, {"duration": 4, "start_time": "2025-03-17T19:02:05.739Z"}, {"duration": 8, "start_time": "2025-03-17T19:02:05.745Z"}, {"duration": 58, "start_time": "2025-03-17T19:02:05.754Z"}, {"duration": 115, "start_time": "2025-03-17T19:02:05.814Z"}, {"duration": 20, "start_time": "2025-03-17T19:02:05.931Z"}, {"duration": 25, "start_time": "2025-03-17T19:02:06.012Z"}, {"duration": 100, "start_time": "2025-03-17T19:02:06.113Z"}, {"duration": 98, "start_time": "2025-03-17T19:02:06.218Z"}, {"duration": 124, "start_time": "2025-03-17T19:02:06.321Z"}, {"duration": 68995, "start_time": "2025-03-17T19:02:06.449Z"}, {"duration": 10, "start_time": "2025-03-17T19:03:15.446Z"}, {"duration": 5636, "start_time": "2025-03-17T19:35:47.530Z"}, {"duration": 257, "start_time": "2025-03-17T19:35:53.169Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.429Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.430Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.431Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.432Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.433Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.434Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.436Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.437Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.438Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.439Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.440Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.441Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.442Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.443Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.444Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.445Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.446Z"}, {"duration": 0, "start_time": "2025-03-17T19:35:53.447Z"}, {"duration": 941, "start_time": "2025-03-17T19:45:17.331Z"}, {"duration": 3991, "start_time": "2025-03-17T19:45:23.123Z"}, {"duration": 16, "start_time": "2025-03-17T19:45:27.116Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.134Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.135Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.136Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.137Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.138Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.139Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.141Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.142Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.143Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.144Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.146Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.148Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.150Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.151Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.152Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.152Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.153Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.155Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.156Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.157Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.158Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.159Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.160Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.161Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:27.162Z"}, {"duration": 1864, "start_time": "2025-03-17T19:45:36.773Z"}, {"duration": 798, "start_time": "2025-03-17T19:45:38.640Z"}, {"duration": 2012, "start_time": "2025-03-17T19:45:39.440Z"}, {"duration": 26, "start_time": "2025-03-17T19:45:41.454Z"}, {"duration": 13, "start_time": "2025-03-17T19:45:41.482Z"}, {"duration": 3, "start_time": "2025-03-17T19:45:41.498Z"}, {"duration": 15, "start_time": "2025-03-17T19:45:41.504Z"}, {"duration": 4, "start_time": "2025-03-17T19:45:41.520Z"}, {"duration": 3, "start_time": "2025-03-17T19:45:41.526Z"}, {"duration": 8, "start_time": "2025-03-17T19:45:41.531Z"}, {"duration": 4, "start_time": "2025-03-17T19:45:41.541Z"}, {"duration": 3, "start_time": "2025-03-17T19:45:41.547Z"}, {"duration": 3, "start_time": "2025-03-17T19:45:41.553Z"}, {"duration": 4, "start_time": "2025-03-17T19:45:41.559Z"}, {"duration": 7, "start_time": "2025-03-17T19:45:41.565Z"}, {"duration": 3, "start_time": "2025-03-17T19:45:41.613Z"}, {"duration": 4, "start_time": "2025-03-17T19:45:41.618Z"}, {"duration": 8, "start_time": "2025-03-17T19:45:41.624Z"}, {"duration": 22, "start_time": "2025-03-17T19:45:41.633Z"}, {"duration": 136, "start_time": "2025-03-17T19:45:41.656Z"}, {"duration": 31, "start_time": "2025-03-17T19:45:41.794Z"}, {"duration": 98, "start_time": "2025-03-17T19:45:41.827Z"}, {"duration": 105, "start_time": "2025-03-17T19:45:41.929Z"}, {"duration": 88, "start_time": "2025-03-17T19:45:42.036Z"}, {"duration": 124, "start_time": "2025-03-17T19:45:42.126Z"}, {"duration": 612, "start_time": "2025-03-17T19:45:42.252Z"}, {"duration": 0, "start_time": "2025-03-17T19:45:42.866Z"}, {"duration": 70830, "start_time": "2025-03-17T19:48:43.694Z"}, {"duration": 1909, "start_time": "2025-03-17T19:58:14.111Z"}, {"duration": 825, "start_time": "2025-03-17T19:58:16.022Z"}, {"duration": 309, "start_time": "2025-03-17T19:58:16.849Z"}, {"duration": 16, "start_time": "2025-03-17T19:58:17.161Z"}, {"duration": 12, "start_time": "2025-03-17T19:58:17.178Z"}, {"duration": 20, "start_time": "2025-03-17T19:58:17.191Z"}, {"duration": 16, "start_time": "2025-03-17T19:58:17.212Z"}, {"duration": 5, "start_time": "2025-03-17T19:58:17.230Z"}, {"duration": 3, "start_time": "2025-03-17T19:58:17.237Z"}, {"duration": 10, "start_time": "2025-03-17T19:58:17.244Z"}, {"duration": 4, "start_time": "2025-03-17T19:58:17.256Z"}, {"duration": 5, "start_time": "2025-03-17T19:58:17.261Z"}, {"duration": 4, "start_time": "2025-03-17T19:58:17.267Z"}, {"duration": 41, "start_time": "2025-03-17T19:58:17.273Z"}, {"duration": 8, "start_time": "2025-03-17T19:58:17.315Z"}, {"duration": 4, "start_time": "2025-03-17T19:58:17.324Z"}, {"duration": 3, "start_time": "2025-03-17T19:58:17.331Z"}, {"duration": 9, "start_time": "2025-03-17T19:58:17.336Z"}, {"duration": 24, "start_time": "2025-03-17T19:58:17.347Z"}, {"duration": 139, "start_time": "2025-03-17T19:58:17.373Z"}, {"duration": 21, "start_time": "2025-03-17T19:58:17.513Z"}, {"duration": 87, "start_time": "2025-03-17T19:58:17.536Z"}, {"duration": 105, "start_time": "2025-03-17T19:58:17.625Z"}, {"duration": 93, "start_time": "2025-03-17T19:58:17.731Z"}, {"duration": 126, "start_time": "2025-03-17T19:58:17.825Z"}, {"duration": 69480, "start_time": "2025-03-17T19:58:18.013Z"}, {"duration": 20, "start_time": "2025-03-17T19:59:27.495Z"}, {"duration": 69047, "start_time": "2025-03-17T20:00:04.851Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}